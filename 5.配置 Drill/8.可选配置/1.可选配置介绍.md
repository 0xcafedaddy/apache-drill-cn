# 可选配置介绍

Drill 提供了一些可选配置，你可以启用，禁止，或者修改。修改某些配置选项可以提升 Drill 性能。一些配置选项在 ``` /conf ``` 目录的 ``` drill-
env.sh ``` 和 ``` drill-override.conf ``` 文件中。如果存在 ``` /etc/drill/conf ```，Drill 会加载该目录下的资源。否则，Drill 会加载 ``` <drill_installation_directory>/conf ``` 本地的资源。

系统可选表包含的信息是关于系统和会话的选项。系统启动表包含的信息是关于 Drill 启动选项。在 [启动可选项](2.启动可选项.md)，涵盖了如何去配置和可视化关键的启动项。下表列出了按字母顺序排列的系统选项，并提供了一个简短的支持选项的说明。

## 系统选项

系统可选表列出了以下可选项，你可以设置系统或会话可选项，在 [计划和执行可选项](3.计划和执行可选项.md) 一节中有描述。

| 名称 | 默认 | 注释 |
| -- | -- | -- |
|drill.exec.functions.cast_empty_string_to_null| FALSE | 在一个文本文件中，把空字段作为 NULL 来代替空字符串。|
|drill.exec.storage.file.partition.column.label| dir|目录中的目录层次的列标签，在一个目录中的文件的查询结果。接受字符串输入。|
|exec.enable_union_type|FALSE| 启用 Avro 连接类型。|
|exec.errors.verbose|FALSE|详细的输出切换执行的错误消息。|
|exec.java_compiler|DEFAULT|在当前的会话中，切换 DEFAULT, JDK, 和 JANINO 模式。使用 JANINO 作为默认的代码生成器，否则使用 JDK 去编译。|
|exec.java_compiler_debug|TRUE|在运行生成代码时，详细输出调试级别的编译错误信息。|
|exec.java_compiler_janino_maxsize|262144|看 exec.java_compiler 选项的注释。允许输入类型为 LONG。|
|exec.max_hash_table_size|1073741824|哈希表中 buckets 结束大小。范围：0 - 1073741824。|
|exec.min_hash_table_size|65536|用于哈希表的 buckets 起始大小。增加可用内存可以提升性能。当你有大量的内存供 Drill 使用，增加你的聚合或 JOIN。范围：0 - 1073741824。|
|exec.queue.enable|FALSE|改变查询队列的状态。FALSE 表示允许不限制当前查询。|
|exec.queue.large|10|在当前集群设置最大查询量。范围：0-1000|
|exec.queue.small|100|在当前集群设置最小查询量。范围：0-1001|
|exec.queue.threshold|30000000|设置队列阀值，这取决于在队列中的查询的复杂性，用于确定查询是大还是小。复杂的查询有较高的阈值。范围：0-9223372036854775807|
|exec.queue.timeout_millis|300000|查询耗时，范围：0-9223372036854775807|
|exec.schedule.assignment.old|FALSE|当没有工作单位被分配给一个小碎片时，特别是当文件的数量远远大于碎片片段的数目时，使用该属性以防止查询失败|
|exec.storage.enable_new_text_reader|TRUE|启用文本读属性，使用标准的 RFC 4180 编译 text/csv 文件。|
|new_view_default_permissions|700|使用 Unix 权限系统，设置视图权限。|
|planner.add_producer_consumer|FALSE|从磁盘增加预读取数据，禁止从内存中读取。|
|planner.affinity_factor|1.2|节点到端点是有力的，同时创建任务。允许输入的类型为 DOUBLE|
|planner.broadcast_factor|1|用于影响记录的广播的启发式参数作为查询的一部分。|
|planner.broadcast_threshold|10000000|允许广播的最大记录数。超过100万的记录，Drill 会重新 shuffle 数据，范围： 0-2147483647|
|planner.disable_exchanges|FALSE|切换到一个随机的交换状态散列。|
|planner.enable_broadcast_join|TRUE|改变聚合和 JOIN 的状态，广播 JOIN 可以用于哈希 JOIN、合并 JOIN 和嵌套循环 JOIN。用于将大（事实）表 JOIN 到相对小（纬度）表中。不要禁用。|
|planner.enable_constant_folding|TRUE|如果一个滤波器的条件的一个侧面是一个常量表达式，常量折叠计算在规划阶段中的表达式，并用常量值替换表达式。例如，Drill 可以重写 WHERE age + 5 < 42 为 WHERE age < 37|
|planner.enable_decimal_data_type|FALSE|FALSE 表示禁止 DECIMAL 数据类型，包含从 Hive 或 Parquet 中强制转换成 DECIMAL 或是可读的 DECIMAL 类型。|
|planner.enable_demux_exchange|FALSE|切换复分离器的状态。|
|planner.enable_hash_single_key|TRUE|每个哈希键与一个值关联。|
|planner.enable_hashagg|TRUE|启用哈系聚合；否则，Drill 是一个分类聚合。Drill 不写磁盘，推荐这样做。|
|planner.enable_hashjoin|TRUE|启用内存哈希连接。Drill 假定有足够的内存来完成的查询，并尝试使用最快的操作完成计划内的左，右，或全外连接。不写磁盘。禁用哈希连接，允许 Drill 在小内存中管理大数据。|
|planner.enable_hashjoin_swap|TRUE|在规划阶段，可考虑多个连接顺序序列。可能会对性能有影响，由于不准确的估计行计数，特别是在 filter，JOIN 或聚合。|
|planner.enable_hep_join_opt||在 JOIN 中启用启发式计划。|
|planner.enable_mergejoin|TRUE|排序操作。合并连接用于内部连接，左，右外部联接。对合并连接的输入必须进行排序。它读取的排序的输入流，并找到匹配的行。写入磁盘。|
|planner.enable_multiphase_agg|TRUE|每一个小的片段会在第一步进行局部聚合，使用 GROUP BY 对其他碎片进行部分汇总，所有的碎片进行全面聚合使用这个数据。|
|planner.enable_mux_exchange|TRUE|切换散列复用交换的状态。|
|planner.enable_nestedloopjoin|TRUE|分类排序。写磁盘。|
|planner.enable_nljoin_for_scalar_only|TRUE|支持嵌套循环连接规划,为了能够在 WHERE 后面使用 NOT-IN, Inequality, Cartesian, 和 uncorrelated。|
|planner.enable_streamagg|TRUE|分类排序。写磁盘。|
|planner.identifier_max_length|1024|因为选择名称本身是标识符，所以需要一个最小长度。|
|planner.join.hash_join_swap_margin_factor|10|在规划阶段考虑的连接顺序序列的数目。|
|planner.join.row_count_estimate_factor|1|在规划阶段考虑多个连接顺序序列时，调整估计行数的因素。|
|planner.memory.average_field_width|8|用于估计内存需求。|
|planner.memory.enable_memory_estimation|FALSE|评估内存状态，重新规划查询。启用时，Drill 保守估计内存需要，通常不包含操作计划和负面的性能影响。|
|planner.memory.hash_agg_table_factor|1.1|影响哈希聚合表大小的一个启发式值。|
|planner.memory.hash_join_table_factor|1.1|影响哈希聚合表大小的一个启发式值。|
|planner.memory.max_query_memory_per_node|2147483648 字节|为每个节点的一个查询设置内存的最大估计数。如果估计太低，Drill 会在没有约束的内存中重新计划查询。|
|planner.memory.non_blocking_operators_memory|64|每个节点存储额外的查询是非阻塞的。这个选项仅用于存储使用的是目前的估计。范围：0～2048 MB|
|planner.memory_limit|268435456 字节|定义分配给用于规划的查询的最大内存，当多个请求同时运行，每个查询分配的内存量就是这个参数设置的值，增加这个参数的值并重新运行查询，如果由于内存不足会导致分区失败。|
|planner.nestedloopjoin_factor|100|影响嵌套循环连接的启发式值。|
|planner.partitioner_sender_max_threads|8|排队队列的线程上限。|
|planner.partitioner_sender_set_threads|-1|重写用于发送批处理的线程数，设置 -1 表示禁用。通常是不变的。|
|planner.partitioner_sender_threads_factor|2|启发式参数用于影响最终的线程数。值越高，线程数越少。|
|planner.producer_consumer_queue_size|10|从磁盘中对记录进行批处理查询执行，有多少数据取多少数据。队列的大小越大，队列和全局查询执行的内存量越大。|
|planner.slice_target|100000|记录数量操纵片段内之前，Drill 的并行操作。|
|planner.width.max_per_node|3|可以在节点上运行的一个查询的最大线程数。切片是一个单独的线程。这个数字表示每一个节点上查询的主要片段的最大片数。|
|planner.width.max_per_query|1000|同一个节点的最大值相同，但适用于整个群集执行的查询。|
|security.admin.user_groups|n/a|不支持1.4。一个逗号分隔的管理员组列表，用于 Web 控制台安全。|
|security.admin.users||不支持1.4。给用户赋予管理员权限，用逗号分割。|
|store.format|parquet|用 CREATE TABLE AS (CTAS) 命令，输出数据格式到表中，允许的格式有 parquet, json, psv, csv, 或 tsv。|
|store.hive.optimize_scan_with_native_readers|FALSE|优化读取外部表，使用 Drill 本地读取替换 Hive Serde 接口。（Drill 1.2 或之后版本）|
|store.json.all_text_mode|FALSE|Drill 从 JSON 文件中读取所有的数据。|
|store.json.extended_types|FALSE|大家指定的 JSON 结构，对比基本的 JSON 类型，Drill 序列化存储更多类型的信息。|
|store.json.read_numbers_as_double|FALSE|将数字 decimal 类型按照 DOUBLE 类型读取。|
|store.mongo.all_text_mode|FALSE|和 store.json.all_text_mode  一样，用于 Mongo。|
|store.mongo.read_numbers_as_double|FALSE|和 store.json.read_numbers_as_double 一样。|
|store.parquet.block-size|536870912|设置的字节数小于或等于 MFS，HDFS，或文件系统的块大小。|
|store.parquet.compression|snappy|Parquet 输出的压缩类型，支持：snappy, gzip, none|
|store.parquet.enable_dictionary_encoding|FALSE|内部使用。不能改变。|
|store.parquet.dictionary.page-size|1048576||
|store.parquet.use_new_reader|FALSE|不支持该本版。|
|store.partition.hash_distribute|FALSE|使用一个哈希算法分布在 CTAS 分区键分区操作数据。这是一个测试选项，不要在生产环境中使用。|
|store.text.estimated_row_size_bytes|100|分隔的文本文件中的行的大小的估计，如CSV。越接近实际，查询计划越好。用于所有 CSV 文件在系统/会话的值设置。|
|window.enable|TRUE|启用或禁用窗口函数，在 Drill 1.1 版本和之后的版本。|
