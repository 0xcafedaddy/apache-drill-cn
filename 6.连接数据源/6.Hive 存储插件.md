# Hive 存储插件

Drill 1.1 和之后的版本支持 Hive 1.0。为了访问 Hive 表使用 SerDes 或输入/输出格式，所有的正在运行的 Drillbit 服务节点，在 ``` <drill_installation_directory>/jars/3rdparty ``` 文件下，必需包含 SerDes 或输入输出格式的 ``` JAR ``` 文件。

在 Drill Web 控制台，选择 Storage 栏，对 Hive 存储插件进行更新。从 Drill Web 控制台中的列出禁止的存储插件中，点击 ``` hive ``` 的 “Update” 按钮进行配置。默认的配置信息如下所示：
```json
{
  "type": "hive",
  "enabled": false,
  "configProps": {
    "hive.metastore.uris": "",
    "javax.jdo.option.ConnectionURL": "jdbc:derby:;databaseName=../sample-data/drill_hive_db;create=true",
    "hive.metastore.warehouse.dir": "/tmp/drill_hive_wh",
    "fs.default.name": "file:///",
    "hive.metastore.sasl.enabled": "false"
  }
}
```

## 从 Drill 上连接到 Hive 的远程仓库

Hive 远程仓库作为一个独立的服务运行。Drill 能够通过 Hive 远程仓库的 Thrift 服务进行查询。元数据服务与 Hive 的数据库通过 JDBC 进行数据交互。

按照下面的步骤来使 Drill 连接到 Hive 的元数据服务。Drill 的 Hive 存储插件配置中提供了连接的参数。如果你不查询 Hive 表，而使用了 HBaseStorageHandler，你已经完成了 Hive 存储插件的配置；否则，如果你查询 Hive 表使用了 HBaseStorageHandler，你需要增加 ZooKeeper 的数量和端口属性。HBaseStorageHandler 需要这些属性。Drill 发现 HBase 服务使用的这些属性。如果你使用 HBase 存储插件，使用相同的 ZooKeeper 数量和端口在 HBase 存储插件中，这里前提是你 Hive 的查询和 HBase 的数据源相同。

```
注释：在验证 Hive 元数据服务之前，你必需启动 Hive 的远程元数据服务。
```

### Hive 远程元数据配置

为了让 Drill 连接到远程的 Hive 元数据：
  1. 在你的 Hive 节点上启动 ``` hive.metastore.uris ```，命令如下所示：
  ```bash
  hive --service metastore &
  ```
  2. 在 Drill Web 控制台，进入到 “Storage” 栏。
  3. 在列出的存储插件中，点击 ``` hive ``` 的 “Update” 按钮。
  4. 在配置窗口，增加 ``` Thrift URI ``` 和 ``` hive.metastore.uris ``` 的端口。例如：
  ```
  ...
     "configProps": {
     "hive.metastore.uris": "thrift://<host>:<port>",
  ...
  ```
  5. 改变默认的文件位置来满足你的环境；例如，改变 ``` "fs.default.name" ``` 属性，将 ``` "file:///" ``` 改为 ``` hdfs:// ``` 或者是 ```  hdfs://<host name>:<port> ```。``` fs.default.name ``` 包含主机名和端口，必需指明主控制节点。例如：
  ```
  {
    "type": "hive",
    "enabled": false,
    "configProps": {
    "hive.metastore.uris": "thrift://hdfs41:9083",
    "hive.metastore.sasl.enabled": "false",
    "fs.default.name": "hdfs://10.10.10.41/"
    }
  }
  ```
  6. 如故你不查询 Hive 表而使用了 HBaseStorageHandler，跳过该步骤；否则，增加 ZooKeeper 的主机名（数量）和端口号，例如 2181 端口。
  ```
  {
    "type": "hive",
    "enabled": false,
    "configProps": {
    .
    .
    .
      "hbase.zookeeper.quorum": "zkhost1,zkhost2,zkhost3",
      "hbase.zookeeper.property.clientPort:" "2181"
    }
  }
  ```
  7. 点击 “Enable”。

## 连接到 Hive 的嵌入模式元数据中

Hive 元数据配置嵌入在 Drill 进程中。配置嵌入元数据在集群中仅仅运行单个 Drillbit 并让其仅仅用于测试。不能将 Hive 嵌入元数据用于生产环境。

在 Drill Web 控制台提供了元数据库的配置项。在你配置一个嵌入 Hive 元数据时，验证驱动是否存在于 ``` /<drill installation directory>/lib/ ```。如果驱动不存在，复制驱动到 Drill 节点的 ``` /<drill installation directory>/lib/ ``` 目录中。更多存储类型和配置信息，请参考 [Hive 元数据管理员](https://cwiki.apache.org/confluence/display/Hive/AdminManual+MetastoreAdmin)。

## Hive 嵌入元数据配置

为了配置嵌入的 Hive 元数据，完成以下步骤：
  1. 在 Drill Web 控制台，进入到 “Storage ” 栏。
  2. 在列出的存储插件中，点击 ``` hive ``` 的 “Update” 按钮。
  3. 在配置窗口，增加数据库配置。
    示例：
    ```json
    {
      "type": "hive",
      "enabled": false,
      "configProps": {
        "hive.metastore.uris": "",
        "javax.jdo.option.ConnectionURL": "jdbc:<database>://<host:port>/<metastore database>",
        "hive.metastore.warehouse.dir": "/tmp/drill_hive_wh",
        "fs.default.name": "file:///",
        "hive.metastore.sasl.enabled": "false"
      }
    }
    ```
    4. 改变 ``` "fs.default.name" ``` 属性。该值需要一个可用的文件系统的 URI 地址。例如，改变本地文件系统 URI ``` "file:///" ``` 为 HDFS 的 URI 地址 ``` hdfs:// ```，或者是 HDFS 的一个 NameNode：``` hdfs://<hostname>:<port> ```
    5. 点击 “Enable”。
“javax.jdo.option.ConnectionURL” 上可能 MySQL 数据库中存储者元数据。Hive 元数据服务提供访问物理 DB 的权限，像 MySQL。MySQL 存储者元数据。

在配置完 Hive 存储插件后，你可以开始查询 Hive 表。
